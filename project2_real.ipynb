{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tennissta99660/LLM_fine_tune_for_classification/blob/main/project2_real.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please download the dataset by opening the link below\n",
        "https://drive.google.com/file/d/11xGSTxTIX482w6wBCPDpbN4iv0100yHJ/view?usp=sharing\n",
        "\n"
      ],
      "metadata": {
        "id": "hhf0WoWM8_ri"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9fZhRu89HnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "HQDYQh7jxitb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde1531b-d61b-4409-d33f-4d82065103d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzmgA-DRghSO",
        "outputId": "60b28bf7-5d1c-41e2-fb74-86046f92ad2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VAOPuuLRRHw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# 3. Set file path to your dataset\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Suicide_Ideation_Dataset.csv'\n",
        "\n",
        "# 4. Load the dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 5. Shuffle the DataFrame\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKhti3__ldfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "IMDB_data_set_file_path = '/content/drive/MyDrive/Colab Notebooks/Suicide_Ideation_Dataset.csv'\n",
        "df = pd.read_csv(IMDB_data_set_file_path)\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vDeB471BvImC",
        "outputId": "c545aafc-0b2f-4908-b8ca-b3b69a2ca339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Tweet  \\\n",
              "0                                     making some lunch   \n",
              "1                           @Alexia You want his money.   \n",
              "2     @dizzyhrvy that crap took me forever to put to...   \n",
              "3     @jnaylor #kiwitweets Hey Jer! Since when did y...   \n",
              "4     Trying out &quot;Delicious Library 2&quot; wit...   \n",
              "...                                                 ...   \n",
              "1782    i have forgotten how much i love my Nokia N95-1   \n",
              "1783  Starting my day out with a positive attitude! ...   \n",
              "1784  @belledame222 Hey, it's 5 am...give a girl som...   \n",
              "1785  2 drunken besties stumble into my room and we ...   \n",
              "1786  @dancingbonita &quot;I friggin love you!!!&quo...   \n",
              "\n",
              "                      Suicide  \n",
              "0            Not Suicide post  \n",
              "1            Not Suicide post  \n",
              "2     Potential Suicide post   \n",
              "3            Not Suicide post  \n",
              "4            Not Suicide post  \n",
              "...                       ...  \n",
              "1782         Not Suicide post  \n",
              "1783         Not Suicide post  \n",
              "1784         Not Suicide post  \n",
              "1785         Not Suicide post  \n",
              "1786         Not Suicide post  \n",
              "\n",
              "[1787 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fef4044-73ed-4eec-bbfc-6ec8489b9555\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Suicide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>making some lunch</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Alexia You want his money.</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@dizzyhrvy that crap took me forever to put to...</td>\n",
              "      <td>Potential Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@jnaylor #kiwitweets Hey Jer! Since when did y...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trying out &amp;quot;Delicious Library 2&amp;quot; wit...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>i have forgotten how much i love my Nokia N95-1</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1783</th>\n",
              "      <td>Starting my day out with a positive attitude! ...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1784</th>\n",
              "      <td>@belledame222 Hey, it's 5 am...give a girl som...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1785</th>\n",
              "      <td>2 drunken besties stumble into my room and we ...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1786</th>\n",
              "      <td>@dancingbonita &amp;quot;I friggin love you!!!&amp;quo...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1787 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fef4044-73ed-4eec-bbfc-6ec8489b9555')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fef4044-73ed-4eec-bbfc-6ec8489b9555 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fef4044-73ed-4eec-bbfc-6ec8489b9555');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-359a936a-51b4-49c5-8fad-b145a8d6f2e1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-359a936a-51b4-49c5-8fad-b145a8d6f2e1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-359a936a-51b4-49c5-8fad-b145a8d6f2e1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ca1a8dc9-0658-437d-a045-08bdf0fa0627\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ca1a8dc9-0658-437d-a045-08bdf0fa0627 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1787,\n  \"fields\": [\n    {\n      \"column\": \"Tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1777,\n        \"samples\": [\n          \"@Farbelowaverag1,,And I just dont want to fucking be here anymore. Please someone just fucking end me because I know itll be worse for everyone if I do it myself and fuck do I want to but please please someone just kill me please\",\n          \"RT @cparham65: Liberals say conservatives are evil. NOTHING\\u00e2\\u0080\\u0099s further from the truth! We believe in \\u00e2\\u0080\\u009clive &amp; let live\\u00e2\\u0080\\u009d. Libs think that big\\u00e2\\u0080\\u00a6\",\n          \"@rowanberry ohhh sending loads of Positive vibes your way\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Suicide\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Potential Suicide post \",\n          \"Not Suicide post\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove leading/trailing spaces from all entries in the 'Suicide' column\n",
        "df[\"Suicide\"] = df[\"Suicide\"].str.strip()\n",
        "\n",
        "# Now check the counts again\n",
        "print(df[\"Suicide\"].value_counts())\n",
        "num_pos = df[df[\"Suicide\"] == \"Potential Suicide post\"].shape[0]\n",
        "num_neg = df[df[\"Suicide\"] == \"Not Suicide post\"].shape[0]\n",
        "print(\"Potential Suicide post:\", num_pos)\n",
        "print(\"Not Suicide post:\", num_neg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia1ij3Mmmf1P",
        "outputId": "63bf5298-7b83-4782-acb1-4a8eda0f7d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suicide\n",
            "Not Suicide post          1127\n",
            "Potential Suicide post     660\n",
            "Name: count, dtype: int64\n",
            "Potential Suicide post: 660\n",
            "Not Suicide post: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Suicide\"].value_counts())\n",
        "num_pos = df[df[\"Suicide\"] == \"Potential Suicide post\"].shape[0]\n",
        "print(\"Potential Suicide post:\", num_pos)\n",
        "num_neg = df[df[\"Suicide\"] == \"Not Suicide post\"].shape[0]\n",
        "print(\"Not Suicide post:\", num_neg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9oCPLbEXG36",
        "outputId": "cf2d4beb-b8ac-4a7f-e19d-89e3c7342ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suicide\n",
            "Not Suicide post          1127\n",
            "Potential Suicide post     660\n",
            "Name: count, dtype: int64\n",
            "Potential Suicide post: 660\n",
            "Not Suicide post: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to prevent certain cells from being executed twice\n",
        "\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "executed_cells = set()\n",
        "\n",
        "@register_line_cell_magic\n",
        "def run_once(line, cell):\n",
        "    if line not in executed_cells:\n",
        "        get_ipython().run_cell(cell)\n",
        "        executed_cells.add(line)\n",
        "    else:\n",
        "        print(f\"Cell '{line}' has already been executed.\")"
      ],
      "metadata": {
        "id": "yndfes0YYNvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Suicide_Ideation_Dataset.csv\")\n",
        "\n",
        "# Strip leading/trailing whitespace from the 'Suicide' column\n",
        "df[\"Suicide\"] = df[\"Suicide\"].str.strip()\n",
        "\n",
        "def create_balanced_dataset(df):\n",
        "    # Find the number of positive samples\n",
        "    num_pos = df[df[\"Suicide\"] == \"Potential Suicide post\"].shape[0]\n",
        "    # Randomly sample the same number of negative samples\n",
        "    neg_subset = df[df[\"Suicide\"] == \"Not Suicide post\"].sample(num_pos, random_state=123)\n",
        "    # Combine both to create a balanced DataFrame\n",
        "    balanced_df = pd.concat([neg_subset, df[df[\"Suicide\"] == \"Potential Suicide post\"]])\n",
        "    # Shuffle the result\n",
        "    balanced_df = balanced_df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "    return balanced_df\n",
        "\n",
        "# Usage\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Suicide\"].value_counts())\n",
        "balanced_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "sq5M7raSYNsK",
        "outputId": "1919878d-cf35-433e-ad0d-ad58f1646d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suicide\n",
            "Not Suicide post          660\n",
            "Potential Suicide post    660\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet                 Suicide\n",
              "0  @drrnlvngstn can i have yours? clouds have com...        Not Suicide post\n",
              "1  whoever replied i cant see it but just kno i s...  Potential Suicide post\n",
              "2  @TennisGrapevine \"Thousands of dead children\",...  Potential Suicide post\n",
              "3                              I hate myself so much  Potential Suicide post\n",
              "4  @LozzaBlack About time! You should always list...        Not Suicide post"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f47e08fe-971a-4d7e-87d9-a92ee588b815\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Suicide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@drrnlvngstn can i have yours? clouds have com...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>whoever replied i cant see it but just kno i s...</td>\n",
              "      <td>Potential Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TennisGrapevine \"Thousands of dead children\",...</td>\n",
              "      <td>Potential Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I hate myself so much</td>\n",
              "      <td>Potential Suicide post</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@LozzaBlack About time! You should always list...</td>\n",
              "      <td>Not Suicide post</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f47e08fe-971a-4d7e-87d9-a92ee588b815')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f47e08fe-971a-4d7e-87d9-a92ee588b815 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f47e08fe-971a-4d7e-87d9-a92ee588b815');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5ebc8bcb-e3c6-4643-b519-7fa091360649\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ebc8bcb-e3c6-4643-b519-7fa091360649')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5ebc8bcb-e3c6-4643-b519-7fa091360649 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 1320,\n  \"fields\": [\n    {\n      \"column\": \"Tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1312,\n        \"samples\": [\n          \"This was a relationship she might want to pursue if he wasn't involved in something illegal.\",\n          \"@robjjones Moody Woods is absolutely awesome\",\n          \"@MissxMarisa Oh sounds like a top movie Really? I don't know who that is but they should hah.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Suicide\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Potential Suicide post\",\n          \"Not Suicide post\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any leading/trailing spaces just in case\n",
        "balanced_df[\"Suicide\"] = balanced_df[\"Suicide\"].str.strip()\n",
        "\n",
        "# Map string labels to integers\n",
        "balanced_df[\"Suicide\"] = balanced_df[\"Suicide\"].map({\n",
        "    \"Not Suicide post\": 0,\n",
        "    \"Potential Suicide post\": 1\n",
        "})\n"
      ],
      "metadata": {
        "id": "FOGSjWaFZi0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map string labels to integers\n",
        "label_map = {\"Potential Suicide post\": 1, \"Not Suicide post\": 0}\n",
        "df[\"Suicide\"] = df[\"Suicide\"].str.strip().map(label_map)\n"
      ],
      "metadata": {
        "id": "6MHb_gggp8W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E40y6ELbaCsl",
        "outputId": "2dab40f5-5f99-475c-89bd-0078ae07dfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Tweet  Suicide\n",
              "0     @drrnlvngstn can i have yours? clouds have com...        0\n",
              "1     whoever replied i cant see it but just kno i s...        1\n",
              "2     @TennisGrapevine \"Thousands of dead children\",...        1\n",
              "3                                 I hate myself so much        1\n",
              "4     @LozzaBlack About time! You should always list...        0\n",
              "...                                                 ...      ...\n",
              "1315  Im exhausted to the point where I NEED my peac...        1\n",
              "1316  Dang man IÃ¢Â€Â™m so god damn insecure :// sigh I...        1\n",
              "1317                                        got a crush        0\n",
              "1318  i keep repeating to myself kill yourself kill ...        1\n",
              "1319  at this point i dont even mind the pain i just...        1\n",
              "\n",
              "[1320 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39a17859-d404-4a98-9179-064961fb210f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Suicide</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@drrnlvngstn can i have yours? clouds have com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>whoever replied i cant see it but just kno i s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@TennisGrapevine \"Thousands of dead children\",...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I hate myself so much</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@LozzaBlack About time! You should always list...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1315</th>\n",
              "      <td>Im exhausted to the point where I NEED my peac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1316</th>\n",
              "      <td>Dang man IÃ¢Â€Â™m so god damn insecure :// sigh I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1317</th>\n",
              "      <td>got a crush</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>i keep repeating to myself kill yourself kill ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1319</th>\n",
              "      <td>at this point i dont even mind the pain i just...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1320 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39a17859-d404-4a98-9179-064961fb210f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39a17859-d404-4a98-9179-064961fb210f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39a17859-d404-4a98-9179-064961fb210f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ffd878f-3074-4966-824d-adb025657fd7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ffd878f-3074-4966-824d-adb025657fd7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ffd878f-3074-4966-824d-adb025657fd7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e8186929-9571-40c5-b71c-09f71eb20d49\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('balanced_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e8186929-9571-40c5-b71c-09f71eb20d49 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('balanced_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 1320,\n  \"fields\": [\n    {\n      \"column\": \"Tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1312,\n        \"samples\": [\n          \"This was a relationship she might want to pursue if he wasn't involved in something illegal.\",\n          \"@robjjones Moody Woods is absolutely awesome\",\n          \"@MissxMarisa Oh sounds like a top movie Really? I don't know who that is but they should hah.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Suicide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "LCQqD96PjAuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIZkO3GtxWw9",
        "outputId": "c5504a60-287e-44ff-b551-3e46ad6de6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class Suicide(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts, ensuring inputs to tokenizer.encode are strings\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(str(text)) for text in self.data[\"Tweet\"] # Convert to string\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "        # Extract and potentially convert labels\n",
        "        self.labels = self.data[\"Suicide\"].tolist()\n",
        "        self._convert_labels_if_needed()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.labels[index]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)  # Ensure label is an integer\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length >= max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n",
        "\n",
        "    def _convert_labels_if_needed(self):\n",
        "        \"\"\"\n",
        "        Converts labels to integers if they are not already.\n",
        "        Handles potential issues like leading/trailing whitespace.\n",
        "        \"\"\"\n",
        "        # Check if labels need conversion (if any label is not an integer)\n",
        "        if not all(isinstance(label, int) for label in self.labels):\n",
        "            # Apply conversion to all labels to ensure consistency\n",
        "            self.labels = [int(float(str(label).strip())) for label in self.labels]"
      ],
      "metadata": {
        "id": "xL6UhCEWxgV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Suicide(\n",
        "    csv_file=\"/content/train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioctfal1JnGi",
        "outputId": "a9ea5802-d29e-496c-90a1-eb6897719967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = Suicide(\n",
        "    csv_file=\"/content/validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = Suicide(\n",
        "    csv_file=\"/content/test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "cv8vdOicJoCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "   # Load the dataset\n",
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "   # Check for invalid values in the 'Suicide' column\n",
        "invalid_labels = train_data[~train_data[\"Suicide\"].isin([0, 1])]\n",
        "\n",
        "   # Print invalid rows\n",
        "print(invalid_labels)"
      ],
      "metadata": {
        "id": "2d7NHIRuTWJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a8cc77-4f15-4af1-ec87-38a4eb901a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Tweet, Suicide]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "   # Load the dataset\n",
        "train_data = pd.read_csv(\"/content/train.csv\")\n",
        "\n",
        "   # Check for invalid values in the 'Suicide' column\n",
        "invalid_labels = train_data[~train_data[\"Suicide\"].isin([0, 1])]\n",
        "\n",
        "   # Print invalid rows\n",
        "print(invalid_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgAzM392seqp",
        "outputId": "6d0ebb7b-ed0c-4009-f818-4554ddf01704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Tweet, Suicide]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Suicide\"].isna().sum())\n",
        "print(df[\"Suicide\"].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7lNS_j4sqXX",
        "outputId": "68056054-676b-487a-af9a-ea83497c4e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 4\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "yjaQDYSOAi-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "id": "JExc93Q6A9QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a7ddbe-66d7-47a0-ab14-9a4d1afd2f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([4, 229])\n",
            "Label batch dimensions torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "id": "COTK_uQBBIuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf7062e-aeec-4716-9155-a7157fcb61f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230 training batches\n",
            "33 validation batches\n",
            "67 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "O_p39QR5Ciwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18cb898-e79c-46b9-dddc-53dc332e7f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        with urllib.request.urlopen(download_url) as response:\n",
        "            # Get the total file size from headers, defaulting to 0 if not present\n",
        "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "            # Check if file exists and has the same size\n",
        "            if os.path.exists(destination):\n",
        "                file_size_local = os.path.getsize(destination)\n",
        "                if file_size == file_size_local:\n",
        "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                    return True  # Indicate success without re-downloading\n",
        "\n",
        "            block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "            # Initialize the progress bar with total file size\n",
        "            progress_bar_description = os.path.basename(download_url)\n",
        "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "                with open(destination, \"wb\") as file:\n",
        "                    while True:\n",
        "                        chunk = response.read(block_size)\n",
        "                        if not chunk:\n",
        "                            break\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "            return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except urllib.error.HTTPError:\n",
        "                pass\n",
        "\n",
        "        # If we reach here, both attempts have failed\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Alternative way using `requests`\n",
        "\"\"\"\n",
        "def download_file(url, destination):\n",
        "    # Send a GET request to download the file in streaming mode\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    # Get the total file size from headers, defaulting to 0 if not present\n",
        "    file_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "    # Check if file exists and has the same size\n",
        "    if os.path.exists(destination):\n",
        "        file_size_local = os.path.getsize(destination)\n",
        "        if file_size == file_size_local:\n",
        "            print(f\"File already exists and is up-to-date: {destination}\")\n",
        "            return\n",
        "\n",
        "    # Define the block size for reading the file\n",
        "    block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "    # Initialize the progress bar with total file size\n",
        "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "        # Open the destination file in binary write mode\n",
        "        with open(destination, \"wb\") as file:\n",
        "            # Iterate over the file data in chunks\n",
        "            for chunk in response.iter_content(block_size):\n",
        "                progress_bar.update(len(chunk))  # Update progress bar\n",
        "                file.write(chunk)  # Write the chunk to the file\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "StDZHRWsHMBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=4096,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "bGG6r0nHKZgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves you\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")"
      ],
      "metadata": {
        "id": "OhjF5UptPNxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "6FNTBKA5Gin5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7999563c-ae22-4add-d466-aad0c319ff3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "_PQqQv7zHFPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c2f632-faf5-4d3b-d989-667a70ef3fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"How is the sentiment of the tweet? Answer with 'Suicidal' or 'not suicidal':\"\n",
        "    \" 'I am feeling down for the past 2 months' \"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSwZ_32mQ5dK",
        "outputId": "e37cbb63-f4cb-41e2-9d43-fccfb539e4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How is the sentiment of the tweet? Answer with 'Suicidal' or 'not suicidal': 'I am feeling down for the past 2 months' _______________________________________________\n",
            "\n",
            "The following is a list of the most common tweets that are being sent to people who are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwFjNdB8SV_W",
        "outputId": "702b6b10-3d15-4111-d2a4-1f03f1e9938d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "CIV6defsUYsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmAr9iE9UiRG",
        "outputId": "46c2112e-6282-41f2-acdb-1e9ab396fbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.out_head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JArD3FQ3Uk6t",
        "outputId": "55279f7c-0e6f-4369-fc6f-92482f577fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=50257, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ],
      "metadata": {
        "id": "l9tcht5IUsOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "EEnU8b1GVFTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZbH66fEVHqh",
        "outputId": "aa2da606-8930-4973-e6d2-839ac67637d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gt8SCdJVJlX",
        "outputId": "e5401cc3-5d31-42da-e831-60207849f62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM3S1QP5VNnc",
        "outputId": "2e0f2226-ae5e-47a8-c929-23dabe5b5259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P90ItzgAVacL",
        "outputId": "c7904b36-3eaf-44f5-f43d-6f9d826a9792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "o9Y5oSJzVfG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
        "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"Running on {device} device.\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "HjV_1Su3MHjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "mRJ_FEEPWDIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as in chapter 5\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "jveTgbVsaW9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "id": "Lmpknm22aad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9108c81d-3dea-4a2c-d2f4-a30ea2e4462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.286\n",
            "Validation loss: 3.280\n",
            "Test loss: 2.527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "uKgevAPaadDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "fh0UYWLBak4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTFMz1vMatDL",
        "outputId": "9e951a1a-92b0-434c-9857-31f3ee2fcde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 1.886, Val loss 3.012\n",
            "Ep 1 (Step 000050): Train loss 0.654, Val loss 0.564\n",
            "Ep 1 (Step 000100): Train loss 0.705, Val loss 0.476\n",
            "Ep 1 (Step 000150): Train loss 0.504, Val loss 0.451\n",
            "Ep 1 (Step 000200): Train loss 0.577, Val loss 0.599\n",
            "Training accuracy: 70.00% | Validation accuracy: 90.00%\n",
            "Ep 2 (Step 000250): Train loss 0.383, Val loss 0.450\n",
            "Ep 2 (Step 000300): Train loss 0.499, Val loss 0.445\n",
            "Ep 2 (Step 000350): Train loss 0.423, Val loss 0.432\n",
            "Ep 2 (Step 000400): Train loss 0.532, Val loss 0.469\n",
            "Ep 2 (Step 000450): Train loss 0.403, Val loss 0.296\n",
            "Training accuracy: 95.00% | Validation accuracy: 95.00%\n",
            "Ep 3 (Step 000500): Train loss 0.348, Val loss 0.378\n",
            "Ep 3 (Step 000550): Train loss 0.443, Val loss 0.346\n",
            "Ep 3 (Step 000600): Train loss 0.627, Val loss 0.297\n",
            "Ep 3 (Step 000650): Train loss 0.310, Val loss 0.317\n",
            "Training accuracy: 70.00% | Validation accuracy: 80.00%\n",
            "Ep 4 (Step 000700): Train loss 0.476, Val loss 0.313\n",
            "Ep 4 (Step 000750): Train loss 0.339, Val loss 0.342\n",
            "Ep 4 (Step 000800): Train loss 0.255, Val loss 0.254\n",
            "Ep 4 (Step 000850): Train loss 0.187, Val loss 0.355\n",
            "Ep 4 (Step 000900): Train loss 0.243, Val loss 0.336\n",
            "Training accuracy: 80.00% | Validation accuracy: 85.00%\n",
            "Ep 5 (Step 000950): Train loss 0.414, Val loss 0.231\n",
            "Ep 5 (Step 001000): Train loss 0.180, Val loss 0.308\n",
            "Ep 5 (Step 001050): Train loss 0.454, Val loss 0.239\n",
            "Ep 5 (Step 001100): Train loss 0.309, Val loss 0.449\n",
            "Training accuracy: 100.00% | Validation accuracy: 80.00%\n",
            "Training completed in 1.74 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dpYRLa86avyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "FBaADUI0ulsa",
        "outputId": "211a9246-ecd5-427e-fa3d-31d071e049cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "0nzLdQMDunsc",
        "outputId": "c0423484-8095-4dc9-c2bc-9d72dbc4c1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA9Wm4UaurPa",
        "outputId": "039daa8b-fe0b-458f-caea-de639429d7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 92.07%\n",
            "Validation accuracy: 88.64%\n",
            "Test accuracy: 88.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
        "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"Suicidal\" if predicted_label == 1 else \"Not Suicidal\""
      ],
      "metadata": {
        "id": "YoSfppp7uuvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"I am feeling excited about my new racket.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGXhy0aKu7EX",
        "outputId": "9160b733-dd77-4a9a-d7a5-14613b82f567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Suicidal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"I am feeling like killing myself\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjRFDn4jvVFu",
        "outputId": "e03592db-1295-48d8-c71d-c492b5b631f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suicidal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "89NCljejMDZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "WwrzR_7CsY8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "ZcjKXWXcviuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EC9O4Og1sbto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}